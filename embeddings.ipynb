{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generating Your First Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e467fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a814a8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d276e4b669d4c10852f4238c4f8f005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036e8be1b089468c83d3018207699d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ffb4223ccf4a96b2f35c556364d469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786f512b5bdd47dc9d9393219a5d1437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2067afd33f2d4633af86844221f900f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71581a0f7b5848a084d271cb3b244416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe33136a441d4a08b5ce4d64f6b27e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544cc0b27c8049879d674a3ebada0e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde8287cc12e4fd085811a9082742c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb84312464244049468b997ae7de9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7018d6b9e37d422582a9204423c0fc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded!\n",
      "Model produces 384 dimensional embeddings\n"
     ]
    }
   ],
   "source": [
    "# Load a small, fast embedding model\n",
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded!\")\n",
    "print(f\"Model produces {model.get_sentence_embedding_dimension()} dimensional embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc3f8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: The cat sat on the mat\n",
      "Embedding shape: (384,)\n",
      "Embedding type: <class 'numpy.ndarray'>\n",
      "\n",
      "First 10 values: [ 0.13040183 -0.01187012 -0.02811703  0.0512387  -0.05597447  0.03019154\n",
      "  0.03016128  0.02469838 -0.01837059  0.05876673]\n"
     ]
    }
   ],
   "source": [
    "# Simple example\n",
    "text = \"The cat sat on the mat\"\n",
    "\n",
    "# Generate embedding\n",
    "embedding = model.encode(text)\n",
    "\n",
    "print(f\"Original text: {text}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"Embedding type: {type(embedding)}\")\n",
    "print(f\"\\nFirst 10 values: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55464941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity function ready!\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two vectors.\n",
    "    \n",
    "    Returns a score between -1 and 1 (higher = more similar)\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "print(\"Similarity function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe4846aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing to: 'The cat sat on the mat'\n",
      "\n",
      "Similarity to 'The cat sat on the mat'\n",
      "Score: 1.000\n",
      "\n",
      "Similarity to 'A feline rested on the rug'\n",
      "Score: 0.564\n",
      "\n",
      "Similarity to 'Dogs are loyal animals'\n",
      "Score: 0.165\n",
      "\n",
      "Similarity to 'Python is a programming language'\n",
      "Score: 0.031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create test sentences\n",
    "sentences = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"A feline rested on the rug\",      # Similar meaning, different words\n",
    "    \"Dogs are loyal animals\",          # Different topic\n",
    "    \"Python is a programming language\" # Completely unrelated\n",
    "]\n",
    "\n",
    "# Generate embeddings for all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Compare first sentence to all others\n",
    "print(\"Comparing to: 'The cat sat on the mat'\\n\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    similarity = cosine_similarity(embeddings[0], embeddings[i])\n",
    "    print(f\"Similarity to '{sentence}'\")\n",
    "    print(f\"Score: {similarity:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74075d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge base: 8 documents\n"
     ]
    }
   ],
   "source": [
    "# Sample knowledge base\n",
    "documents = [\n",
    "    \"Python is a high-level programming language known for simplicity\",\n",
    "    \"Machine learning enables computers to learn from data\",\n",
    "    \"Neural networks are inspired by biological brains\",\n",
    "    \"Dogs are loyal and friendly pets that need exercise\",\n",
    "    \"Cats are independent animals that make great companions\",\n",
    "    \"JavaScript is used for web development and runs in browsers\",\n",
    "    \"Deep learning uses multi-layered neural networks\",\n",
    "    \"Puppies require training and socialization from an early age\"\n",
    "]\n",
    "\n",
    "print(f\"Knowledge base: {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c334c3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for all documents...\n",
      "Created 8 embeddings\n",
      "Each embedding has 384 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all documents\n",
    "print(\"Generating embeddings for all documents...\")\n",
    "doc_embeddings = model.encode(documents)\n",
    "\n",
    "print(f\"Created {len(doc_embeddings)} embeddings\")\n",
    "print(f\"Each embedding has {doc_embeddings[0].shape[0]} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb221ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search function ready!\n"
     ]
    }
   ],
   "source": [
    "def search(query, documents, doc_embeddings, top_k=3):\n",
    "    \"\"\"\n",
    "    Search for documents similar to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query (string)\n",
    "        documents: List of document texts\n",
    "        doc_embeddings: Pre-computed document embeddings\n",
    "        top_k: Number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of (document, similarity_score) tuples\n",
    "    \"\"\"\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = []\n",
    "    for i, doc_emb in enumerate(doc_embeddings):\n",
    "        similarity = cosine_similarity(query_embedding, doc_emb)\n",
    "        similarities.append((documents[i], similarity))\n",
    "    \n",
    "    # Sort by similarity (highest first)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top k results\n",
    "    return similarities[:top_k]\n",
    "\n",
    "print(\"Search function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "277bcb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY: What is artificial intelligence?\n",
      "================================================================================\n",
      "\n",
      "1. (Score: 0.408)\n",
      "   Machine learning enables computers to learn from data\n",
      "\n",
      "2. (Score: 0.395)\n",
      "   Neural networks are inspired by biological brains\n",
      "\n",
      "3. (Score: 0.326)\n",
      "   Python is a high-level programming language known for simplicity\n",
      "\n",
      "================================================================================\n",
      "QUERY: Tell me about pet dogs\n",
      "================================================================================\n",
      "\n",
      "1. (Score: 0.548)\n",
      "   Dogs are loyal and friendly pets that need exercise\n",
      "\n",
      "2. (Score: 0.437)\n",
      "   Puppies require training and socialization from an early age\n",
      "\n",
      "3. (Score: 0.413)\n",
      "   Cats are independent animals that make great companions\n",
      "\n",
      "================================================================================\n",
      "QUERY: How do I code in Python?\n",
      "================================================================================\n",
      "\n",
      "1. (Score: 0.554)\n",
      "   Python is a high-level programming language known for simplicity\n",
      "\n",
      "2. (Score: 0.148)\n",
      "   Puppies require training and socialization from an early age\n",
      "\n",
      "3. (Score: 0.138)\n",
      "   JavaScript is used for web development and runs in browsers\n"
     ]
    }
   ],
   "source": [
    "# Test different queries\n",
    "queries = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"Tell me about pet dogs\",\n",
    "    \"How do I code in Python?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    results = search(query, documents, doc_embeddings, top_k=3)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. (Score: {score:.3f})\")\n",
    "        print(f\"   {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99453c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e448aa561a1a484599e9b652c59e6cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbc6b835a52438dae6c517f7d009d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5434737a921e4127a0d2ef445d2a273a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc7b0bae40b4c6fae35ef3d5dc02e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe418854aec0413fb86467dd98ae0b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bf99e66d884a7ca0fe83b3865435ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d11392e1874d9eb591a5779a3fd861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d245f0fe2b45c6bd03a7a12c405a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f5ed86c7e14ad5b5c4523c3fcdd933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0c0a44100e44dc92ae6b74a90f5d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857e782ce97e49efb67509d413e2ce52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both models loaded!\n",
      "Small model: 384 dimensions\n",
      "Large model: 768 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Load two different models for comparison\n",
    "print(\"Loading models...\\n\")\n",
    "\n",
    "model_small = SentenceTransformer('all-MiniLM-L6-v2')      # 384 dimensions\n",
    "model_large = SentenceTransformer('all-mpnet-base-v2')     # 768 dimensions\n",
    "\n",
    "print(\"Both models loaded!\")\n",
    "print(f\"Small model: {model_small.get_sentence_embedding_dimension()} dimensions\")\n",
    "print(f\"Large model: {model_large.get_sentence_embedding_dimension()} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38707617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing model performance:\n",
      "\n",
      "Pair: 'The dog is running' vs 'A canine is jogging'\n",
      "  Small model: 0.818\n",
      "  Large model: 0.827\n",
      "\n",
      "Pair: 'I love pizza' vs 'Pizza is delicious'\n",
      "  Small model: 0.801\n",
      "  Large model: 0.785\n",
      "\n",
      "Pair: 'Python programming' vs 'Cooking pasta'\n",
      "  Small model: 0.142\n",
      "  Large model: 0.120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare on a similarity task\n",
    "test_pairs = [\n",
    "    (\"The dog is running\", \"A canine is jogging\"),           # Similar\n",
    "    (\"I love pizza\", \"Pizza is delicious\"),                  # Related\n",
    "    (\"Python programming\", \"Cooking pasta\")                  # Unrelated\n",
    "]\n",
    "\n",
    "print(\"Comparing model performance:\\n\")\n",
    "for text1, text2 in test_pairs:\n",
    "    # Small model\n",
    "    emb1_small = model_small.encode([text1, text2])\n",
    "    sim_small = cosine_similarity(emb1_small[0], emb1_small[1])\n",
    "    \n",
    "    # Large model  \n",
    "    emb1_large = model_large.encode([text1, text2])\n",
    "    sim_large = cosine_similarity(emb1_large[0], emb1_large[1])\n",
    "    \n",
    "    print(f\"Pair: '{text1}' vs '{text2}'\")\n",
    "    print(f\"  Small model: {sim_small:.3f}\")\n",
    "    print(f\"  Large model: {sim_large:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a46eccfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRetriever class ready!\n"
     ]
    }
   ],
   "source": [
    "class SimpleRetriever:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize retriever with embedding model.\n",
    "        \"\"\"\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.chunks = []\n",
    "        self.embeddings = None\n",
    "    \n",
    "    def add_documents(self, documents, chunk_size=500):\n",
    "        \"\"\"\n",
    "        Add documents to the retriever (chunks and embeds them).\n",
    "        \"\"\"\n",
    "        # Simple chunking (from Module 2)\n",
    "        for doc in documents:\n",
    "            words = doc.split()\n",
    "            for i in range(0, len(words), chunk_size):\n",
    "                chunk = ' '.join(words[i:i+chunk_size])\n",
    "                self.chunks.append(chunk)\n",
    "        \n",
    "        # Generate embeddings\n",
    "        print(f\"Embedding {len(self.chunks)} chunks...\")\n",
    "        self.embeddings = self.model.encode(self.chunks)\n",
    "        print(f\"Ready! {len(self.chunks)} chunks indexed.\")\n",
    "    \n",
    "    def search(self, query, top_k=3):\n",
    "        \"\"\"\n",
    "        Search for relevant chunks.\n",
    "        \"\"\"\n",
    "        # Embed query\n",
    "        query_embedding = self.model.encode(query)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = []\n",
    "        for i, chunk_emb in enumerate(self.embeddings):\n",
    "            sim = cosine_similarity(query_embedding, chunk_emb)\n",
    "            similarities.append((self.chunks[i], sim))\n",
    "        \n",
    "        # Sort and return top k\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similarities[:top_k]\n",
    "\n",
    "print(\"SimpleRetriever class ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb37d0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 3 chunks...\n",
      "Ready! 3 chunks indexed.\n",
      "\n",
      "================================================================================\n",
      "Query: How do I start learning to code?\n",
      "================================================================================\n",
      "\n",
      "Result 1 (Score: 0.263):\n",
      "Python is a versatile programming language widely used in web development, data science, and automation. Its simple syntax makes it beginner-friendly while remaining powerful for advanced applications.\n",
      "\n",
      "Result 2 (Score: 0.228):\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience. Popular frameworks include TensorFlow, PyTorch, and scikit-learn.\n",
      "\n",
      "================================================================================\n",
      "Query: What is AI and machine learning?\n",
      "================================================================================\n",
      "\n",
      "Result 1 (Score: 0.697):\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience. Popular frameworks include TensorFlow, PyTorch, and scikit-learn.\n",
      "\n",
      "Result 2 (Score: 0.234):\n",
      "Python is a versatile programming language widely used in web development, data science, and automation. Its simple syntax makes it beginner-friendly while remaining powerful for advanced applications.\n",
      "\n",
      "================================================================================\n",
      "Query: Tell me about caring for pets\n",
      "================================================================================\n",
      "\n",
      "Result 1 (Score: 0.432):\n",
      "Dogs are loyal companions that require regular exercise, training, and veterinary care. Different breeds have varying needs and temperaments.\n",
      "\n",
      "Result 2 (Score: 0.119):\n",
      "Python is a versatile programming language widely used in web development, data science, and automation. Its simple syntax makes it beginner-friendly while remaining powerful for advanced applications.\n"
     ]
    }
   ],
   "source": [
    "# Test it with sample documents\n",
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Python is a versatile programming language widely used in web development,\n",
    "    data science, and automation. Its simple syntax makes it beginner-friendly\n",
    "    while remaining powerful for advanced applications.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Machine learning is a subset of artificial intelligence that enables systems\n",
    "    to learn and improve from experience. Popular frameworks include TensorFlow,\n",
    "    PyTorch, and scikit-learn.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Dogs are loyal companions that require regular exercise, training, and\n",
    "    veterinary care. Different breeds have varying needs and temperaments.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Create retriever and add documents\n",
    "retriever = SimpleRetriever()\n",
    "retriever.add_documents(sample_docs, chunk_size=100)\n",
    "\n",
    "# Test searches\n",
    "test_queries = [\n",
    "    \"How do I start learning to code?\",\n",
    "    \"What is AI and machine learning?\",\n",
    "    \"Tell me about caring for pets\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    results = retriever.search(query, top_k=2)\n",
    "    for i, (chunk, score) in enumerate(results, 1):\n",
    "        print(f\"\\nResult {i} (Score: {score:.3f}):\")\n",
    "        print(chunk.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
